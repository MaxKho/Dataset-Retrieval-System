# Dataset Search Engine

Endâ€‘toâ€‘end pipeline for building a **queryâ€“document training set**, fineâ€‘tuning a SPECTERâ€‘2 encoder with Adapter Fusion, and ranking documents for adâ€‘hoc retrieval tasks.  
Everything lives in **src/** â€“ plugâ€‘andâ€‘play from raw data to evaluation reports.

---

## 1Â |Â Setâ€‘up (Conda)

```bash
# create & activate environment (Pythonâ€¯3.10 tested)
conda create -n doc-retrieval python=3.10 -y
conda activate doc-retrieval

# install all Python dependencies
pip install -r requirements.txt

# (optional) expose src/ to Python
export PYTHONPATH="${PWD}/src:${PYTHONPATH}"
```

> **GPU users:** install the matching CUDAâ€‘enabled PyTorch **before** running `pip install`.

---

## 2Â |Â Get the data & model weightsÂ ðŸ“¥

Large files are **not tracked by git**.  
Open `data/README.md` for Googleâ€¯Drive links and SHAâ€‘256 checksums, then:

```bash
cd data
# download the three ZIP archives listed in the README
unzip new-data.zip
unzip precomputed_embeddings.zip
unzip new-weights.zip
```

Your `data/` tree should now match:

```
data/
 â”œâ”€ data/1_raw_data/â€¦
 â”œâ”€ data/3_final_data/doc_embeddings_*.pkl
 â””â”€ weights/best_finetuned_adhoc_query_adapter_*/
```

---

## 3Â |Â Run somethingÂ ðŸš€

### Quick demo (â‰ˆ30â€¯s)

```bash
python src/demo_retrieval.py        --query "graph neural networks for molecule property prediction"
```

Ranks documents with preâ€‘computed embeddings & the best adapters.

### Full pipeline (long)

```bash
python src/main_pipeline.py
```

Reâ€‘creates everything from scratch: merges raw data, generates hard negatives, fineâ€‘tunes adapters, computes embeddings, optimises the scoring function, evaluates.

Key flags:

| flag | default | purpose |
|------|---------|---------|
| `--device` | `cpu` | set `cuda:0` for GPU |
| `--config` | `configs/default.yaml` | override stage parameters |
| `--skip-embedding` | `false` | reuse existing embeddings |

---

## 4Â |Â Outputs

* **Embeddings:** `data/data/3_final_data/doc_embeddings_*.pkl`  
* **Fineâ€‘tuned adapters:** `data/weights/*`  
* **Evaluation reports:** `outputs/evaluation/*.json`

---

## 5Â |Â Troubleshooting

| symptom | fix |
|---------|-----|
| `FileNotFoundError: .../1_raw_data/...` | ensure all ZIPs are unzipped into `data/` |
| `OSError: "cuda" not available` | install CUDAâ€‘compatible PyTorch or use `--device cpu` |
| RAM spikes | run `main_pipeline.py` with partial flags to process chunks |

---

## 6Â |Â Licence & citation

Released under **ApacheÂ 2.0**.  
If you use this code, please cite the accompanying paper (BibTeX in `CITATION.cff`).

Happy retrieving! ðŸŽ‰
